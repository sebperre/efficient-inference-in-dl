Training on GPU...
Iteration 1: Epoch [1/20], Loss: 1.8695
Iteration 1: Epoch [2/20], Loss: 1.4735
Iteration 1: Epoch [3/20], Loss: 1.3364
Iteration 1: Epoch [4/20], Loss: 1.2397
Iteration 1: Epoch [5/20], Loss: 1.1614
Iteration 1: Epoch [6/20], Loss: 1.0932
Iteration 1: Epoch [7/20], Loss: 1.0378
Iteration 1: Epoch [8/20], Loss: 0.9907
Iteration 1: Epoch [9/20], Loss: 0.9436
Iteration 1: Epoch [10/20], Loss: 0.8960
Iteration 1: Epoch [11/20], Loss: 0.8657
Iteration 1: Epoch [12/20], Loss: 0.8272
Iteration 1: Epoch [13/20], Loss: 0.7900
Iteration 1: Epoch [14/20], Loss: 0.7590
Iteration 1: Epoch [15/20], Loss: 0.7243
Iteration 1: Epoch [16/20], Loss: 0.6990
Iteration 1: Epoch [17/20], Loss: 0.6730
Iteration 1: Epoch [18/20], Loss: 0.6448
Iteration 1: Epoch [19/20], Loss: 0.6090
Iteration 1: Epoch [20/20], Loss: 0.6001
Loss on Last Iteration for Training is 375.04592165350914

Iteration 1: Testing on Test Set
Accuracy: 0.7021
Precision: 0.7013
Recall: 0.7021
F1 Score: 0.6994

Classification Report:

              precision    recall  f1-score   support

           0       0.73      0.72      0.73      1000
           1       0.81      0.82      0.82      1000
           2       0.61      0.52      0.56      1000
           3       0.57      0.47      0.52      1000
           4       0.62      0.70      0.66      1000
           5       0.62      0.62      0.62      1000
           6       0.67      0.84      0.75      1000
           7       0.82      0.73      0.77      1000
           8       0.81      0.81      0.81      1000
           9       0.75      0.79      0.77      1000

    accuracy                           0.70     10000
   macro avg       0.70      0.70      0.70     10000
weighted avg       0.70      0.70      0.70     10000

Iteration 2: Epoch [1/20], Loss: 1.8511
Iteration 2: Epoch [2/20], Loss: 1.4347
Iteration 2: Epoch [3/20], Loss: 1.2441
Iteration 2: Epoch [4/20], Loss: 1.1091
Iteration 2: Epoch [5/20], Loss: 1.0076
Iteration 2: Epoch [6/20], Loss: 0.9211
Iteration 2: Epoch [7/20], Loss: 0.8499
Iteration 2: Epoch [8/20], Loss: 0.7804
Iteration 2: Epoch [9/20], Loss: 0.7208
Iteration 2: Epoch [10/20], Loss: 0.6701
Iteration 2: Epoch [11/20], Loss: 0.6196
Iteration 2: Epoch [12/20], Loss: 0.5669
Iteration 2: Epoch [13/20], Loss: 0.5228
Iteration 2: Epoch [14/20], Loss: 0.4893
Iteration 2: Epoch [15/20], Loss: 0.4549
Iteration 2: Epoch [16/20], Loss: 0.4174
Iteration 2: Epoch [17/20], Loss: 0.3940
Iteration 2: Epoch [18/20], Loss: 0.3608
Iteration 2: Epoch [19/20], Loss: 0.3427
Iteration 2: Epoch [20/20], Loss: 0.3274
Loss on Last Iteration for Training is 204.6017949655652

Iteration 2: Testing on Test Set
Accuracy: 0.7350
Precision: 0.7401
Recall: 0.7350
F1 Score: 0.7362

Classification Report:

              precision    recall  f1-score   support

           0       0.81      0.72      0.76      1000
           1       0.83      0.85      0.84      1000
           2       0.67      0.59      0.63      1000
           3       0.52      0.58      0.55      1000
           4       0.65      0.76      0.70      1000
           5       0.64      0.66      0.65      1000
           6       0.83      0.76      0.79      1000
           7       0.81      0.77      0.79      1000
           8       0.84      0.83      0.83      1000
           9       0.81      0.82      0.82      1000

    accuracy                           0.73     10000
   macro avg       0.74      0.73      0.74     10000
weighted avg       0.74      0.73      0.74     10000

Iteration 3: Epoch [1/20], Loss: 1.9752
Iteration 3: Epoch [2/20], Loss: 1.5281
Iteration 3: Epoch [3/20], Loss: 1.3099
Iteration 3: Epoch [4/20], Loss: 1.1372
Iteration 3: Epoch [5/20], Loss: 1.0132
Iteration 3: Epoch [6/20], Loss: 0.9121
Iteration 3: Epoch [7/20], Loss: 0.8247
Iteration 3: Epoch [8/20], Loss: 0.7552
Iteration 3: Epoch [9/20], Loss: 0.6932
Iteration 3: Epoch [10/20], Loss: 0.6431
Iteration 3: Epoch [11/20], Loss: 0.6016
Iteration 3: Epoch [12/20], Loss: 0.5597
Iteration 3: Epoch [13/20], Loss: 0.5230
Iteration 3: Epoch [14/20], Loss: 0.4918
Iteration 3: Epoch [15/20], Loss: 0.4644
Iteration 3: Epoch [16/20], Loss: 0.4302
Iteration 3: Epoch [17/20], Loss: 0.4035
Iteration 3: Epoch [18/20], Loss: 0.3817
Iteration 3: Epoch [19/20], Loss: 0.3632
Iteration 3: Epoch [20/20], Loss: 0.3411
Loss on Last Iteration for Training is 213.1696972027421

Iteration 3: Testing on Test Set
Accuracy: 0.7984
Precision: 0.8017
Recall: 0.7984
F1 Score: 0.7978

Classification Report:

              precision    recall  f1-score   support

           0       0.80      0.86      0.83      1000
           1       0.93      0.87      0.90      1000
           2       0.78      0.66      0.72      1000
           3       0.60      0.65      0.62      1000
           4       0.82      0.70      0.75      1000
           5       0.72      0.71      0.72      1000
           6       0.76      0.90      0.82      1000
           7       0.87      0.84      0.86      1000
           8       0.90      0.87      0.88      1000
           9       0.82      0.92      0.87      1000

    accuracy                           0.80     10000
   macro avg       0.80      0.80      0.80     10000
weighted avg       0.80      0.80      0.80     10000

Iteration 4: Epoch [1/20], Loss: 1.9840
Iteration 4: Epoch [2/20], Loss: 1.5585
Iteration 4: Epoch [3/20], Loss: 1.3567
Iteration 4: Epoch [4/20], Loss: 1.1893
Iteration 4: Epoch [5/20], Loss: 1.0443
Iteration 4: Epoch [6/20], Loss: 0.9227
Iteration 4: Epoch [7/20], Loss: 0.8359
Iteration 4: Epoch [8/20], Loss: 0.7579
Iteration 4: Epoch [9/20], Loss: 0.6971
Iteration 4: Epoch [10/20], Loss: 0.6436
Iteration 4: Epoch [11/20], Loss: 0.5980
Iteration 4: Epoch [12/20], Loss: 0.5556
Iteration 4: Epoch [13/20], Loss: 0.5150
Iteration 4: Epoch [14/20], Loss: 0.4818
Iteration 4: Epoch [15/20], Loss: 0.4489
Iteration 4: Epoch [16/20], Loss: 0.4210
Iteration 4: Epoch [17/20], Loss: 0.4013
Iteration 4: Epoch [18/20], Loss: 0.3752
Iteration 4: Epoch [19/20], Loss: 0.3529
Iteration 4: Epoch [20/20], Loss: 0.3325
Loss on Last Iteration for Training is 207.78430370986462

Iteration 4: Testing on Test Set
Accuracy: 0.8096
Precision: 0.8088
Recall: 0.8096
F1 Score: 0.8067

Classification Report:

              precision    recall  f1-score   support

           0       0.83      0.85      0.84      1000
           1       0.85      0.94      0.89      1000
           2       0.81      0.64      0.72      1000
           3       0.70      0.60      0.65      1000
           4       0.79      0.80      0.79      1000
           5       0.75      0.74      0.74      1000
           6       0.76      0.92      0.83      1000
           7       0.87      0.82      0.84      1000
           8       0.89      0.89      0.89      1000
           9       0.85      0.90      0.87      1000

    accuracy                           0.81     10000
   macro avg       0.81      0.81      0.81     10000
weighted avg       0.81      0.81      0.81     10000

Iteration 5: Epoch [1/20], Loss: 2.0948
Iteration 5: Epoch [2/20], Loss: 1.7177
Iteration 5: Epoch [3/20], Loss: 1.4909
Iteration 5: Epoch [4/20], Loss: 1.3084
Iteration 5: Epoch [5/20], Loss: 1.1477
Iteration 5: Epoch [6/20], Loss: 1.0194
Iteration 5: Epoch [7/20], Loss: 0.9102
Iteration 5: Epoch [8/20], Loss: 0.8157
Iteration 5: Epoch [9/20], Loss: 0.7393
Iteration 5: Epoch [10/20], Loss: 0.6705
Iteration 5: Epoch [11/20], Loss: 0.6162
Iteration 5: Epoch [12/20], Loss: 0.5615
Iteration 5: Epoch [13/20], Loss: 0.5198
Iteration 5: Epoch [14/20], Loss: 0.4747
Iteration 5: Epoch [15/20], Loss: 0.4336
Iteration 5: Epoch [16/20], Loss: 0.4002
Iteration 5: Epoch [17/20], Loss: 0.3657
Iteration 5: Epoch [18/20], Loss: 0.3336
Iteration 5: Epoch [19/20], Loss: 0.3113
Iteration 5: Epoch [20/20], Loss: 0.2819
Loss on Last Iteration for Training is 176.1815166696906

Iteration 5: Testing on Test Set
Accuracy: 0.8176
Precision: 0.8212
Recall: 0.8176
F1 Score: 0.8177

Classification Report:

              precision    recall  f1-score   support

           0       0.84      0.82      0.83      1000
           1       0.94      0.90      0.92      1000
           2       0.71      0.77      0.74      1000
           3       0.66      0.68      0.67      1000
           4       0.75      0.85      0.80      1000
           5       0.82      0.67      0.74      1000
           6       0.89      0.82      0.85      1000
           7       0.88      0.86      0.87      1000
           8       0.82      0.93      0.87      1000
           9       0.90      0.89      0.90      1000

    accuracy                           0.82     10000
   macro avg       0.82      0.82      0.82     10000
weighted avg       0.82      0.82      0.82     10000

Overlap Table

Weaker 0 and Stronger 1
Label       % Weaker of Stronger     % Stronger of Weaker     
--------------------------------------------------------------
0           88.84                    88.11                    
1           91.85                    95.11                    
2           75.17                    84.84                    
3           68.5                     84.32                    
4           82.46                    90.13                    
5           80.3                     86.04                    
6           96.07                    86.75                    
7           88.63                    94.23                    
8           91.59                    94.66                    
9           90.17                    93.58                    
--------------------------------------------------------------
% Weaker of Stronger Total: 86.24
% Stronger of Weaker Total: 90.29

Weaker 0 and Stronger 2
Label       % Weaker of Stronger     % Stronger of Weaker     
--------------------------------------------------------------
0           80.33                    95.44                    
1           88.42                    94.25                    
2           69.7                     88.29                    
3           62.19                    85.38                    
4           80.89                    80.54                    
5           76.22                    88.47                    
6           90.22                    96.09                    
7           83.91                    97.39                    
8           87.9                     94.78                    
9           85.12                    98.74                    
--------------------------------------------------------------
% Weaker of Stronger Total: 81.41
% Stronger of Weaker Total: 92.58

Weaker 0 and Stronger 3
Label       % Weaker of Stronger     % Stronger of Weaker     
--------------------------------------------------------------
0           80.42                    94.33                    
1           84.88                    97.43                    
2           70.2                     86.37                    
3           62.56                    79.66                    
4           77.89                    88.7                     
5           73.05                    87.99                    
6           88.85                    96.21                    
7           84.59                    95.74                    
8           87.02                    95.78                    
9           84.18                    95.84                    
--------------------------------------------------------------
% Weaker of Stronger Total: 80.4
% Stronger of Weaker Total: 92.71

Weaker 0 and Stronger 4
Label       % Weaker of Stronger     % Stronger of Weaker     
--------------------------------------------------------------
0           80.54                    91.01                    
1           86.03                    94.13                    
2           62.86                    92.9                     
3           59.91                    85.81                    
4           75.41                    91.7                     
5           74.7                     81.01                    
6           90.77                    88.4                     
7           81.24                    95.74                    
8           84.76                    97.39                    
9           84.79                    95.47                    
--------------------------------------------------------------
% Weaker of Stronger Total: 78.8
% Stronger of Weaker Total: 91.77

Weaker 1 and Stronger 2
Label       % Weaker of Stronger     % Stronger of Weaker     
--------------------------------------------------------------
0           80.33                    96.23                    
1           91.74                    94.45                    
2           77.42                    86.9                     
3           75.46                    84.17                    
4           88.94                    81.02                    
5           81.4                     88.18                    
6           82.78                    97.64                    
7           87.93                    95.99                    
8           90.55                    94.47                    
9           88.06                    98.42                    
--------------------------------------------------------------
% Weaker of Stronger Total: 84.87
% Stronger of Weaker Total: 92.19

Weaker 1 and Stronger 3
Label       % Weaker of Stronger     % Stronger of Weaker     
--------------------------------------------------------------
0           81.49                    96.37                    
1           87.97                    97.52                    
2           76.76                    83.67                    
3           75.37                    77.97                    
4           85.18                    88.74                    
5           80.19                    90.15                    
6           81.53                    97.77                    
7           88.47                    94.19                    
8           89.39                    95.19                    
9           88.83                    97.45                    
--------------------------------------------------------------
% Weaker of Stronger Total: 84.05
% Stronger of Weaker Total: 92.59

Weaker 1 and Stronger 4
Label       % Weaker of Stronger     % Stronger of Weaker     
--------------------------------------------------------------
0           81.03                    92.33                    
1           89.83                    94.92                    
2           69.22                    90.65                    
3           72.34                    84.17                    
4           82.35                    91.62                    
5           79.64                    80.61                    
6           85.42                    92.14                    
7           86.6                     95.99                    
8           87.24                    97.0                     
9           88.93                    96.48                    
--------------------------------------------------------------
% Weaker of Stronger Total: 82.78
% Stronger of Weaker Total: 92.08

Weaker 2 and Stronger 3
Label       % Weaker of Stronger     % Stronger of Weaker     
--------------------------------------------------------------
0           94.81                    93.6                     
1           91.48                    98.51                    
2           88.14                    85.61                    
3           85.69                    79.48                    
4           81.28                    92.96                    
5           87.2                     90.49                    
6           95.63                    97.22                    
7           95.02                    92.66                    
8           94.58                    96.54                    
9           96.9                     95.11                    
--------------------------------------------------------------
% Weaker of Stronger Total: 91.51
% Stronger of Weaker Total: 92.8

Weaker 2 and Stronger 4
Label       % Weaker of Stronger     % Stronger of Weaker     
--------------------------------------------------------------
0           94.0                     89.41                    
1           92.63                    95.07                    
2           79.74                    93.03                    
3           80.18                    83.64                    
4           77.65                    94.83                    
5           87.57                    81.82                    
6           96.84                    88.56                    
7           92.89                    94.32                    
8           91.57                    97.58                    
9           97.32                    94.46                    
--------------------------------------------------------------
% Weaker of Stronger Total: 89.4
% Stronger of Weaker Total: 91.55

Weaker 3 and Stronger 4
Label       % Weaker of Stronger     % Stronger of Weaker     
--------------------------------------------------------------
0           92.9                     89.5                     
1           97.54                    92.97                    
2           78.44                    94.23                    
3           77.07                    86.69                    
4           86.71                    92.59                    
5           91.32                    82.21                    
6           97.93                    88.09                    
7           91.61                    95.39                    
8           92.86                    96.95                    
9           96.09                    95.02                    
--------------------------------------------------------------
% Weaker of Stronger Total: 90.68
% Stronger of Weaker Total: 91.58

/home/sebperre/programming-projects/efficient-inference-in-dl/iterative_models/cifar_vgg_oracle.py:195: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)
  all_preds.append(int(pred.cpu().numpy()))
/home/sebperre/programming-projects/efficient-inference-in-dl/iterative_models/cifar_vgg_oracle.py:215: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)
  all_preds.append(int(pred.cpu().numpy()))
Model Comparison

Statistic           Best                     Combined                 Difference               
-----------------------------------------------------------------------------------------------
Accuracy (%)        81.76                    82.48                    -0.72                    
Precision (%)       82.1186                  82.5959                  -0.4773                  
Recall (%)          81.76                    82.48                    -0.72                    
F1 (%)              81.7686                  82.4639                  -0.6953                  
Time (s)            11.0178                  8.9353                   2.0824                   
-----------------------------------------------------------------------------------------------

Best Model Class Report
              precision    recall  f1-score   support

           0       0.84      0.82      0.83      1000
           1       0.94      0.90      0.92      1000
           2       0.71      0.77      0.74      1000
           3       0.66      0.68      0.67      1000
           4       0.75      0.85      0.80      1000
           5       0.82      0.67      0.74      1000
           6       0.89      0.82      0.85      1000
           7       0.88      0.86      0.87      1000
           8       0.82      0.93      0.87      1000
           9       0.90      0.89      0.90      1000

    accuracy                           0.82     10000
   macro avg       0.82      0.82      0.82     10000
weighted avg       0.82      0.82      0.82     10000


Combined Model Class Report
              precision    recall  f1-score   support

           0       0.83      0.86      0.84      1000
           1       0.93      0.87      0.90      1000
           2       0.79      0.77      0.78      1000
           3       0.69      0.68      0.68      1000
           4       0.77      0.85      0.81      1000
           5       0.80      0.74      0.77      1000
           6       0.86      0.84      0.85      1000
           7       0.88      0.84      0.86      1000
           8       0.88      0.87      0.88      1000
           9       0.83      0.92      0.87      1000

    accuracy                           0.82     10000
   macro avg       0.83      0.82      0.82     10000
weighted avg       0.83      0.82      0.82     10000

Statistic           Model 1                  Model 2                  Model 3                  Model 4                  
------------------------------------------------------------------------------------------------------------------------
Accuracy (%)        81.76                    81.76                    81.76                    81.76                    
Precision (%)       82.1186                  82.1186                  82.1186                  82.1186                  
Recall (%)          81.76                    81.76                    81.76                    81.76                    
F1 Score (%)        81.7686                  81.7686                  81.7686                  81.7686                  
Time (s)            10.9942                  11.0436                  11.0425                  11.1451                  
------------------------------------------------------------------------------------------------------------------------

Model 1 Class Report
              precision    recall  f1-score   support

           0       0.84      0.82      0.83      1000
           1       0.94      0.90      0.92      1000
           2       0.71      0.77      0.74      1000
           3       0.66      0.68      0.67      1000
           4       0.75      0.85      0.80      1000
           5       0.82      0.67      0.74      1000
           6       0.89      0.82      0.85      1000
           7       0.88      0.86      0.87      1000
           8       0.82      0.93      0.87      1000
           9       0.90      0.89      0.90      1000

    accuracy                           0.82     10000
   macro avg       0.82      0.82      0.82     10000
weighted avg       0.82      0.82      0.82     10000


Model 2 Class Report
              precision    recall  f1-score   support

           0       0.84      0.82      0.83      1000
           1       0.94      0.90      0.92      1000
           2       0.71      0.77      0.74      1000
           3       0.66      0.68      0.67      1000
           4       0.75      0.85      0.80      1000
           5       0.82      0.67      0.74      1000
           6       0.89      0.82      0.85      1000
           7       0.88      0.86      0.87      1000
           8       0.82      0.93      0.87      1000
           9       0.90      0.89      0.90      1000

    accuracy                           0.82     10000
   macro avg       0.82      0.82      0.82     10000
weighted avg       0.82      0.82      0.82     10000


Model 3 Class Report
              precision    recall  f1-score   support

           0       0.84      0.82      0.83      1000
           1       0.94      0.90      0.92      1000
           2       0.71      0.77      0.74      1000
           3       0.66      0.68      0.67      1000
           4       0.75      0.85      0.80      1000
           5       0.82      0.67      0.74      1000
           6       0.89      0.82      0.85      1000
           7       0.88      0.86      0.87      1000
           8       0.82      0.93      0.87      1000
           9       0.90      0.89      0.90      1000

    accuracy                           0.82     10000
   macro avg       0.82      0.82      0.82     10000
weighted avg       0.82      0.82      0.82     10000


Model 4 Class Report
              precision    recall  f1-score   support

           0       0.84      0.82      0.83      1000
           1       0.94      0.90      0.92      1000
           2       0.71      0.77      0.74      1000
           3       0.66      0.68      0.67      1000
           4       0.75      0.85      0.80      1000
           5       0.82      0.67      0.74      1000
           6       0.89      0.82      0.85      1000
           7       0.88      0.86      0.87      1000
           8       0.82      0.93      0.87      1000
           9       0.90      0.89      0.90      1000

    accuracy                           0.82     10000
   macro avg       0.82      0.82      0.82     10000
weighted avg       0.82      0.82      0.82     10000


